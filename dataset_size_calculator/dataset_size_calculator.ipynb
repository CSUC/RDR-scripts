{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Script per extreure les mides dels datasets d'una instància\n",
        "# OBSERVACIÓ:\n",
        "Si teniu dubtes sobre el codi, poseu-vos en contacte amb rdr-contacte@csuc.cat\n",
        "## OBJECTIU DE L'SCRIPT\n",
        "Aquest script permet calcular la mida total dels conjunt de dades (datasets) allotjat a una instància del Repositori de Dades de Recerca (https://dataverse.csuc.cat/). Utilitza l'API de Dataverse per obtenir la mida de tots els fitxers associats als datasets d'una instància i retorna la mida total en bytes, KB, MB o GB.\n"
      ],
      "metadata": {
        "id": "gyMLbpUS8gWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DxW5mewck59m"
      },
      "outputs": [],
      "source": [
        "# @title Instal·leu o actualitzeu les llibreries (feu clic al botó Executar &#x25B6; )\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "def install_packages(b):\n",
        "    \"\"\"\n",
        "    Function to install or update required Python packages.\n",
        "\n",
        "    Args:\n",
        "    b (widget): Button widget that triggers the installation process.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    clear_output(wait=True)\n",
        "    !pip install --upgrade pip -q  # Upgrade pip silently\n",
        "    !pip install pyDataverse -q    # Install or update pyDataverse silently\n",
        "    !pip install requests -q       # Install or update requests silently\n",
        "    print(\"Les llibreries s'han descarregat o actualitzat correctament.\")\n",
        "\n",
        "# Displaying installation message\n",
        "display(HTML(\"<p style='font-size:14px;'><b>Feu clic al botó següent per instal·lar les llibreries necessàries.</b></p>\"))\n",
        "\n",
        "# Creating installation button\n",
        "install_button = widgets.Button(description='Instal·lar llibreries')\n",
        "install_button.on_click(install_packages)\n",
        "\n",
        "# Displaying the installation button\n",
        "display(install_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyQh0bc2nm67",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Feu clic al botó Executar &#x25B6; , ompliu el token i trieu les institucions i les metadades\n",
        "import subprocess\n",
        "import smtplib\n",
        "import os\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "from pyDataverse.api import NativeApi, DataAccessApi, MetricsApi\n",
        "from pyDataverse.models import Dataverse\n",
        "import pandas as pd\n",
        "import requests\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "class UtilsConnection:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def call_api(self, url, method, data=None):\n",
        "        payload = {}\n",
        "        headers = {'X-Dataverse-key': config.get_token()}\n",
        "\n",
        "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "\n",
        "class Config:\n",
        "    def __init__(self, api_url, logger, token):\n",
        "        self.api_url = api_url\n",
        "        self.logger = logger\n",
        "        self.token = token\n",
        "\n",
        "    def get_app_config(self):\n",
        "        return self\n",
        "\n",
        "    def get_api_url(self):\n",
        "        return self.api_url\n",
        "\n",
        "    def get_logger(self):\n",
        "        return self.logger\n",
        "\n",
        "    def get_token(self):\n",
        "        return self.token\n",
        "\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, config, identifier):\n",
        "        self.config = config\n",
        "        self.list_datasets = []\n",
        "        self.list_dataverse_children = []\n",
        "        self.identifier = identifier\n",
        "\n",
        "    def update_list_dataset(self, dataset_id):\n",
        "        self.list_datasets.append(dataset_id)\n",
        "\n",
        "    def update_list_dataverse_children(self, dataseverse_id):\n",
        "        self.list_dataverse_children.append(dataseverse_id)\n",
        "\n",
        "    def remove_id_list_dataverse_children(self, dataseverse_id):\n",
        "        self.list_dataverse_children.remove(dataseverse_id)\n",
        "\n",
        "    def get_list_datasets(self):\n",
        "        return self.list_datasets\n",
        "\n",
        "    def get_list_dataverse_children(self):\n",
        "        return self.list_dataverse_children\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.list_datasets)\n",
        "\n",
        "    def create_list_datasets(self, identifier):\n",
        "\n",
        "        conn = UtilsConnection(self.config)\n",
        "\n",
        "        url_api = f\"{self.config.get_api_url()}/api/dataverses/{identifier}/contents\"\n",
        "        object_json = conn.call_api(url_api, \"GET\")\n",
        "\n",
        "        if object_json:\n",
        "            self.config.get_logger().info(f\"Reading the API values\")\n",
        "            array_json = object_json.get(\"data\", {})\n",
        "\n",
        "            for value in array_json:\n",
        "                if value['type'] == 'dataverse':\n",
        "                    self.update_list_dataverse_children(value['id'])\n",
        "                elif value['type'] == 'dataset' and value['protocol'] == 'doi':\n",
        "                    self.update_list_dataset(value['protocol'] + ':' + value['authority'] + '/' + value['identifier'])\n",
        "        else:\n",
        "            self.config.get_logger().error(f\"Call API ERROR\")\n",
        "\n",
        "        if not identifier == self.identifier:\n",
        "            self.remove_id_list_dataverse_children(identifier)\n",
        "\n",
        "        if len(self.get_list_dataverse_children()) != 0:\n",
        "\n",
        "            self.create_list_datasets(self.get_list_dataverse_children()[0])\n",
        "\n",
        "def filemetadata(base_url, token, doi, filemetadata_keys, filemetadata_values):\n",
        "    \"\"\"\n",
        "    Function to extract metadata for files associated with a dataset identified by its DOI.\n",
        "\n",
        "    Parameters:\n",
        "    - base_url: str. Base URL of the Dataverse instance.\n",
        "    - token: str. API token for authentication.\n",
        "    - doi: str. DOI of the dataset.\n",
        "    - filemetadata_keys: list. List to store file metadata keys.\n",
        "    - filemetadata_values: list. List to store file metadata values.\n",
        "\n",
        "    Returns:\n",
        "    - None. Updates the provided lists with extracted file metadata.\n",
        "    \"\"\"\n",
        "    from pyDataverse.api import NativeApi, DataAccessApi\n",
        "    from pyDataverse.models import Dataverse\n",
        "\n",
        "    # Instantiate API objects for accessing Dataverse\n",
        "    api = NativeApi(base_url, token)\n",
        "    data_api = DataAccessApi(base_url, token)\n",
        "\n",
        "    try:\n",
        "        # Retrieve dataset metadata\n",
        "        if(doi != 'doi:10.34810/data1872'):\n",
        "          dataset = api.get_dataset(doi)\n",
        "          # Iterate through files and extract metadata\n",
        "          for i in range(len(dataset.json()['data']['latestVersion']['files'])):\n",
        "              filemetadata_resp = dataset.json()['data']['latestVersion']['files'][i]['dataFile']\n",
        "              filemetadata_keys_aux = list(filemetadata_resp.keys())\n",
        "              filemetadata_values_aux = list(filemetadata_resp.values())\n",
        "              filemetadata_keys.append(filemetadata_keys_aux)\n",
        "              filemetadata_values.append(filemetadata_values_aux)\n",
        "    except KeyError:\n",
        "        print('There was an error reading metadata for the files of the dataset: ' + doi)\n",
        "\n",
        "# Configuration and execution\n",
        "import logging\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Ask the user for the token\n",
        "token = input(\"Introduïu el vostre token i premeu enter: \")\n",
        "\n",
        "# Use the token in your configuration\n",
        "config = Config(api_url=\"https://dataverse.csuc.cat/\", logger=logger, token=token)\n",
        "\n",
        "# List of institutions\n",
        "institucions = [\n",
        "    'UB', 'UAB', 'UPC', 'UPF', 'UdG', 'UdL', 'URV', 'UOC', 'UVIC-UCC',\n",
        "    'URL', 'UIC', 'UIB', 'Agrotecnio', 'CED', 'CRAG', 'CREAF', 'CRM', 'CTFC',\n",
        "    'i2CAT', 'I3PT', 'IBEC', 'IBEI', 'ICAC-CERCA', 'ICFO-CERCA', 'ICN2',\n",
        "    'ICRA-CERCA', 'IDIBAPS', 'IDIBELL', 'IDIBGI-CERCA', 'IFAE', 'IJC','IRSantPau','CVC','IRSJD',\n",
        "    'IPHES-CERCA', 'IRBBarcelona-CERCA', 'IRB', 'IRSICAIXA', 'IRTA',\n",
        "    'ISGLOBAL', 'VHIR'\n",
        "]\n",
        "# Add an option for selecting all\n",
        "options_institucions = ['Totes les institucions'] + institucions\n",
        "\n",
        "# Create widgets for instructions and selections\n",
        "instruction_text_institucions = widgets.HTML(\n",
        "    value=\"<b>Trieu una o més institucions:</b>\"\n",
        ")\n",
        "\n",
        "# Create the widget for multiple selection of institutions\n",
        "institucions_widget = widgets.SelectMultiple(\n",
        "    options=options_institucions,\n",
        "    value=[],\n",
        "    description='Institucions:',\n",
        "    disabled=False\n",
        ")\n",
        "# Function to save selected institutions and print them\n",
        "opcions = set()\n",
        "def save_selection_institucions(change):\n",
        "    global opcions\n",
        "    selected = set(change['new'])\n",
        "\n",
        "    if 'Totes les institucions' in selected:\n",
        "        opcions = set(institucions)  # Select all institutions if 'Totes les institucions' is chosen\n",
        "    else:\n",
        "        opcions.update(selected)  # Update the set with new selections\n",
        "\n",
        "    print(f\"Institucions: {list(opcions)}\")\n",
        "\n",
        "# Function to clear the selection and reset the institutions widget\n",
        "def restart_selection_institucions(button):\n",
        "    global opcions\n",
        "    institucions_widget.value = []  # Clear the selections in the widget\n",
        "    opcions.clear()  # Clear the global opcions set\n",
        "    print(\"La selecció de la institució s'ha restablert.\")\n",
        "\n",
        "# Observe changes in the widget selection for institutions\n",
        "institucions_widget.observe(save_selection_institucions, names='value')\n",
        "\n",
        "# Create a button to restart the selection for institutions\n",
        "restart_button_institucions = widgets.Button(description=\"Reiniciar la selecció d'institucions\")\n",
        "restart_button_institucions.on_click(restart_selection_institucions)\n",
        "\n",
        "# Display the widgets and button with instructions\n",
        "\n",
        "display(instruction_text_institucions, institucions_widget, restart_button_institucions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbQQlz92FxAA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Un cop escollides les institucions, ciqueu el botó &#x25B6; per generar el taulell de mides dels datasets\n",
        "\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_dataset_sizes(base_url, token,doi):\n",
        "    api = NativeApi(base_url, token)\n",
        "    dataset = api.get_dataset(doi)\n",
        "    filemetadata_keys = []\n",
        "    filemetadata_values = []\n",
        "    filemetadata(base_url, token, doi, filemetadata_keys, filemetadata_values)\n",
        "\n",
        "    if not filemetadata_keys or not filemetadata_values:\n",
        "        return 0, 0  # Retorna 0 si no hay metadatos\n",
        "\n",
        "    def get_index(key_list, key):\n",
        "        return key_list.index(key) if key in key_list else None\n",
        "\n",
        "    def get_size(entry, key_list):\n",
        "        original_index = get_index(key_list, 'originalFileSize')\n",
        "        file_index = get_index(key_list, 'filesize')\n",
        "        if original_index is not None and isinstance(entry[original_index], int):\n",
        "            return entry[original_index]\n",
        "        return entry[file_index] if file_index is not None and isinstance(entry[file_index], int) else 0\n",
        "\n",
        "    sizes = [get_size(entry, filemetadata_keys[i]) for i, entry in enumerate(filemetadata_values)]\n",
        "    total_original_size_bytes = sum(sizes)\n",
        "\n",
        "    filesize_index = get_index(filemetadata_keys[0], 'filesize') if filemetadata_keys else None\n",
        "    total_archival_size_bytes = sum(entry[filesize_index] for entry in filemetadata_values if filesize_index is not None and isinstance(entry[filesize_index], int))\n",
        "\n",
        "    return total_original_size_bytes, total_archival_size_bytes\n",
        "\n",
        "def format_size(size_in_bytes):\n",
        "    units = [\"Bytes\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
        "    size = float(size_in_bytes)\n",
        "    unit_index = 0\n",
        "    while size >= 1024 and unit_index < len(units) - 1:\n",
        "        size /= 1024\n",
        "        unit_index += 1\n",
        "    return f\"{size:.2f}\".replace('.', ','), units[unit_index]  # Replaces dot with comma\n",
        "\n",
        "base_url=\"https://dataverse.csuc.cat/\"\n",
        "data = []\n",
        "for element in opcions:\n",
        "    processor = DatasetProcessor(config, element)\n",
        "    processor.create_list_datasets(element)\n",
        "    sigles=element\n",
        "    for i in processor.get_list_datasets():\n",
        "      original_size, archival_size = get_dataset_sizes(base_url,token,i)\n",
        "      formatted_original, unit_original = format_size(original_size)\n",
        "      formatted_archival, unit_archival = format_size(archival_size)\n",
        "      data.append([i, sigles, original_size, archival_size, float(formatted_original.replace(',', '.')), unit_original, float(formatted_archival.replace(',', '.')), unit_archival])\n",
        "df = pd.DataFrame(data, columns=[\"DOI\",\"Institució\", \"Original Size (Bytes)\", \"Archival Size (Bytes)\",  \"Formatted Original Size\", \"Unit (Original Size)\", \"Formatted Archival Size\", \"Unit (Archival Size)\" ])\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clicar el botó &#x25B6; per guardar les dades en un fitxer excel.\n",
        "from google.colab import files\n",
        "# Save the DataFrame to an Excel file\n",
        "excel_filename = 'mida_datasets.xlsx'\n",
        "df.to_excel(excel_filename, index=False)\n",
        "\n",
        "# Provide download link for the file\n",
        "files.download(excel_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Kg4s-N0JZ9Z4",
        "outputId": "4cc82f60-b430-43eb-e5b8-484812481c1c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63b7cb49-540f-4e5d-a89e-1ea402bd3864\", \"mida_datasets.xlsx\", 5853)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}