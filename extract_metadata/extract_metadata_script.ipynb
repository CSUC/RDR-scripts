{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSUC/RDR-scripts/blob/main/extract_metadata/extract_metadata_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "041f626a",
      "metadata": {
        "id": "041f626a"
      },
      "source": [
        "# Extreure metadades a un fitxer tabular"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987673eb",
      "metadata": {
        "id": "987673eb"
      },
      "source": [
        "OBSERVACIÓ: Si teniu dubtes del codi, contactar amb rdr-contacte@csuc.cat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f68b40",
      "metadata": {
        "id": "42f68b40"
      },
      "source": [
        "## OBJECTIU DE L'SCRIPT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ef8f4cc",
      "metadata": {
        "id": "1ef8f4cc"
      },
      "source": [
        "L'objectiu principal d'aquest script és exportar les metadades d'un dataset a un fitxer tabular CSV o excel."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f38fe0",
      "metadata": {
        "id": "52f38fe0"
      },
      "source": [
        "## IMPORTANT: Només Emplenar les variables token i doi i executar tot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dccbe3e8",
      "metadata": {
        "cellView": "form",
        "id": "dccbe3e8"
      },
      "outputs": [],
      "source": [
        "# @title First click the &#x25B6; button to execute the script. </p> Then, enter the token (If you don't have your API token, you can get it from the following link <a href='https://dataverse.csuc.cat/dataverseuser.xhtml?selectTab=apiTokenTab' target='_blank'>Get API Token</a>).</p> After that, enter the LAST DIGITS of the DOI (for example, if the DOI ends in <strong>dataXYZ</strong>, only write the number <strong>XYZ</strong> ).</p> Finally click <strong>Download</strong> to download the file.\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Function to install required packages\n",
        "def install_packages():\n",
        "    \"\"\"\n",
        "    Function to install or update necessary Python packages.\n",
        "    \"\"\"\n",
        "    # Upgrade pip first\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"-q\"])\n",
        "\n",
        "    # Install the required libraries\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyDataverse\", \"-q\"])\n",
        "\n",
        "    print(\"Libraries have been downloaded or updated.\")\n",
        "\n",
        "# Install libraries if they are not installed already\n",
        "try:\n",
        "    import pyDataverse\n",
        "except ImportError:\n",
        "    print(\"Installing libraries...\")\n",
        "    install_packages()\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, FileLink\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from pyDataverse.api import NativeApi, DataAccessApi\n",
        "from pyDataverse.models import Dataverse\n",
        "import pandas as pd\n",
        "\n",
        "# Provide input values\n",
        "token = \"\"  # @param {type:\"string\"}\n",
        "identifier = \"\"  # @param {type:\"string\"}\n",
        "base_url = \"https://dataverse.csuc.cat/\"\n",
        "doi = 'doi:10.34810/data'+identifier\n",
        "\n",
        "def extract_value(data_dict):\n",
        "    \"\"\"\n",
        "    Function to extract all keys and values from a JSON metadata dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - data_dict: dict. JSON metadata dictionary.\n",
        "\n",
        "    Returns:\n",
        "    - type_names: list. List of type names extracted from the metadata.\n",
        "    - values: list. List of values extracted from the metadata.\n",
        "    \"\"\"\n",
        "    if isinstance(data_dict, dict):\n",
        "        type_names = []\n",
        "        values = []\n",
        "        for key, value in data_dict.items():\n",
        "            if key == 'typeName' and 'value' in data_dict:\n",
        "                if isinstance(data_dict['value'], list):\n",
        "                    for v in data_dict['value']:\n",
        "                        type_names.append(data_dict['typeName'])\n",
        "                        values.append(v)\n",
        "                else:\n",
        "                    type_names.append(data_dict['typeName'])\n",
        "                    values.append(data_dict['value'])\n",
        "            elif isinstance(value, dict) and 'typeName' in value and 'value' in value:\n",
        "                type_names.append(value['typeName'])\n",
        "                values.append(value['value'])\n",
        "            elif isinstance(value, str) and key == 'typeName':\n",
        "                type_names.append(value)\n",
        "                values.append(value)\n",
        "            else:\n",
        "                extracted_type_names, extracted_values = extract_value(value)\n",
        "                type_names += extracted_type_names\n",
        "                values += extracted_values\n",
        "        return type_names, values\n",
        "    elif isinstance(data_dict, list):\n",
        "        type_names = []\n",
        "        values = []\n",
        "        for item in data_dict:\n",
        "            extracted_type_names, extracted_values = extract_value(item)\n",
        "            type_names += extracted_type_names\n",
        "            values += extracted_values\n",
        "        return type_names, values\n",
        "    else:\n",
        "        return [], []\n",
        "\n",
        "def exportmetadata(base_url, token, doi,\n",
        "                   citation_keys, citation_values,\n",
        "                   geo_keys, geo_values,\n",
        "                   social_keys, social_values,\n",
        "                   astronomy_keys, astronomy_values,\n",
        "                   biomedical_keys, biomedical_values,\n",
        "                   journal_keys, journal_values,\n",
        "                   computationalworkflow_keys, computationalworkflow_values,\n",
        "                   LocalContextsCVoc_keys, LocalContextsCVoc_values,\n",
        "                   darwincore_keys, darwincore_values):\n",
        "    \"\"\"\n",
        "    Export metadata from a Dataverse dataset using its DOI.\n",
        "\n",
        "    Parameters:\n",
        "        (same as original, see above)\n",
        "\n",
        "    Returns:\n",
        "        None. Populates provided lists with extracted metadata.\n",
        "    \"\"\"\n",
        "    from pyDataverse.api import NativeApi, DataAccessApi\n",
        "    import os\n",
        "\n",
        "    api = NativeApi(base_url, token)\n",
        "\n",
        "    # Metadata blocks mapping: (block_name, keys_list, values_list)\n",
        "    metadata_blocks = [\n",
        "        (\"citation\", citation_keys, citation_values),\n",
        "        (\"geospatial\", geo_keys, geo_values),\n",
        "        (\"socialscience\", social_keys, social_values),\n",
        "        (\"astrophysics\", astronomy_keys, astronomy_values),\n",
        "        (\"biomedical\", biomedical_keys, biomedical_values),\n",
        "        (\"journal\", journal_keys, journal_values),\n",
        "        (\"computationalworkflow\", computationalworkflow_keys, computationalworkflow_values),\n",
        "        (\"LocalContextsCVoc\", LocalContextsCVoc_keys, LocalContextsCVoc_values),\n",
        "        (\"darwincore\", darwincore_keys, darwincore_values)\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        dataset = api.get_dataset(doi)\n",
        "        metadata = dataset.json()['data']['latestVersion']['metadataBlocks']\n",
        "\n",
        "        for block_name, keys_list, values_list in metadata_blocks:\n",
        "            if block_name in metadata:\n",
        "                fields = metadata[block_name]['fields']\n",
        "                extracted_keys, extracted_values = extract_value(fields)\n",
        "                keys_list.extend(extracted_keys)\n",
        "                values_list.extend(extracted_values)\n",
        "                for item in fields:\n",
        "                    if isinstance(item['value'], str):\n",
        "                        try:\n",
        "                            index = keys_list.index(item['typeName'])\n",
        "                            values_list[index] = item['value']\n",
        "                        except ValueError:\n",
        "                            pass  # typeName wasn't added by extract_value\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting metadata for DOI {doi}: {e}\")\n",
        "\n",
        "def extract_metadata(data,\n",
        "                     citation_keys, citation_values,\n",
        "                     geo_keys, geo_values,\n",
        "                     social_keys, social_values,\n",
        "                     astronomy_keys, astronomy_values,\n",
        "                     biomedical_keys, biomedical_values,\n",
        "                     journal_keys, journal_values,\n",
        "                     computationalworkflow_keys, computationalworkflow_values,\n",
        "                     LocalContextsCVoc_keys, LocalContextsCVoc_values,\n",
        "                     darwincore_keys, darwincore_values,\n",
        "                     flatten_dicts=False):\n",
        "    \"\"\"\n",
        "    Extracts metadata key-value pairs and appends to `data`.\n",
        "    If `flatten_dicts` is True, nested dictionaries are flattened into separate key-value pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata_blocks = [\n",
        "        (citation_keys, citation_values),\n",
        "        (geo_keys, geo_values),\n",
        "        (social_keys, social_values),\n",
        "        (astronomy_keys, astronomy_values),\n",
        "        (biomedical_keys, biomedical_values),\n",
        "        (journal_keys, journal_values),\n",
        "        (computationalworkflow_keys, computationalworkflow_values),\n",
        "        (LocalContextsCVoc_keys, LocalContextsCVoc_values),\n",
        "        (darwincore_keys, darwincore_values),\n",
        "    ]\n",
        "\n",
        "    for keys, values in metadata_blocks:\n",
        "        for key, value in zip(keys, values):\n",
        "            if isinstance(value, dict) and flatten_dicts:\n",
        "                # Flatten nested dict (optional)\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    flat_key = f\"{key}.{sub_key}\"\n",
        "                    data.append([flat_key, sub_value])\n",
        "            elif not isinstance(value, dict):\n",
        "                data.append([key, value])\n",
        "\n",
        "\n",
        "# Checking if both DOI and token are provided\n",
        "if not doi or not token:\n",
        "    print(\"Please enter both DOI and Token.\")\n",
        "else:\n",
        "    # Extracting path from DOI\n",
        "    path = doi.replace(\"doi:10.34810/\", \"\")\n",
        "    # Initializing API access\n",
        "    api = NativeApi(base_url, token)\n",
        "    data_api = DataAccessApi(base_url, token)\n",
        "    # Getting dataset metadata\n",
        "    dataset = api.get_dataset(doi)\n",
        "    # Lists for metadata\n",
        "    citation_keys, geo_keys, social_keys, astronomy_keys, biomedical_keys, journal_keys, computationalworkflow_keys, LocalContextsCVoc_keys, darwincore_keys  = [[] for _ in range(9)]\n",
        "    citation_values, geo_values, social_values, astronomy_values, biomedical_values, journal_values, computationalworkflow_values, LocalContextsCVoc_values, darwincore_values = [[] for _ in range(9)]\n",
        "    data=[]\n",
        "    # Exporting metadata\n",
        "    exportmetadata(base_url, token, doi, citation_keys, citation_values, geo_keys, geo_values, social_keys,\n",
        "                      social_values, astronomy_keys, astronomy_values, biomedical_keys, biomedical_values,\n",
        "                      journal_keys, journal_values,computationalworkflow_keys, computationalworkflow_values,\n",
        "                      LocalContextsCVoc_keys, LocalContextsCVoc_values, darwincore_keys, darwincore_values)\n",
        "    extract_metadata(\n",
        "                      data,\n",
        "                      citation_keys, citation_values,\n",
        "                      geo_keys, geo_values,\n",
        "                      social_keys, social_values,\n",
        "                      astronomy_keys, astronomy_values,\n",
        "                      biomedical_keys, biomedical_values,\n",
        "                      journal_keys, journal_values,\n",
        "                      computationalworkflow_keys, computationalworkflow_values,\n",
        "                      LocalContextsCVoc_keys, LocalContextsCVoc_values,\n",
        "                      darwincore_keys, darwincore_values,\n",
        "                      flatten_dicts=False  # Optional: True to flatten nested dicts\n",
        "                  )\n",
        "    # Creating a DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Metadata', 'Value'])\n",
        "\n",
        "    # Writing DataFrame to a CSV file\n",
        "    df.to_csv(path + '_' + 'metadata.csv', index=False)\n",
        "\n",
        "    # Writing DataFrame to an Excel file\n",
        "    excel_file = path + '_' + 'metadata.xlsx'\n",
        "    df.to_excel(excel_file, index=False)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Running in Google Colab\n",
        "    # Providing a download button for CSV file\n",
        "    csv_download_button = widgets.Button(description=\"Download metadata (CSV)\")\n",
        "    display(csv_download_button)\n",
        "\n",
        "    # Function to be executed when the CSV download button is clicked\n",
        "    def on_csv_download_button_click(b):\n",
        "        # Downloading the metadata CSV file in Google Colab\n",
        "        files.download(path + '_' + 'metadata.csv')\n",
        "\n",
        "    # Event handler for the CSV download button\n",
        "    csv_download_button.on_click(on_csv_download_button_click)\n",
        "\n",
        "    # Providing a download button for Excel file\n",
        "    excel_download_button = widgets.Button(description=\"Download metadata (Excel)\")\n",
        "    display(excel_download_button)\n",
        "\n",
        "    # Function to be executed when the Excel download button is clicked\n",
        "    def on_excel_download_button_click(b):\n",
        "        # Downloading the metadata Excel file in Google Colab\n",
        "        files.download(excel_file)\n",
        "\n",
        "    # Event handler for the Excel download button\n",
        "    excel_download_button.on_click(on_excel_download_button_click)\n",
        "\n",
        "else:\n",
        "    # Running in Jupyter Notebook\n",
        "    # Providing a download link for CSV file\n",
        "    csv_download_link = FileLink(path + '_' + 'metadata.csv', result_html_prefix=\"Click here to download metadata (CSV): \")\n",
        "    display(csv_download_link)\n",
        "\n",
        "    # Providing a download link for Excel file\n",
        "    excel_download_link = FileLink(excel_file, result_html_prefix=\"Click here to download metadata (Excel): \")\n",
        "    display(excel_download_link)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}